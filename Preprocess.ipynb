{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "it's generally recommended to convert MP3 files to WAV format, preferably with a consistent sampling rate (e.g., 16kHz, mono) to ensure compatibility with training models"
      ],
      "metadata": {
        "id": "PUUe11mKfFLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps for Data Preprocessing:**\n",
        "\n",
        "---\n",
        "\n",
        "1. Convert MP3 files to WAV (16kHz, mono)\n",
        "\n",
        "2. Load and inspect the dataset (TSV files)\n",
        "\n",
        "3. Align audio files with text transcriptions\n",
        "\n",
        "4. Remove invalid or low-quality samples\n",
        "\n",
        "5. Normalize and clean text data\n",
        "\n",
        "6. Split the train data into Train/Validation"
      ],
      "metadata": {
        "id": "K0GLTb01fOF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BwkSgHWPfs9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google Drive & Set Paths**"
      ],
      "metadata": {
        "id": "oerVXOWyfrqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset paths\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Capstone/cv-corpus-20.0-2024-12-06/hy-AM\"\n",
        "CLIPS_PATH = os.path.join(DATASET_PATH, \"clips\")\n",
        "TSV_FILES = [f for f in os.listdir(DATASET_PATH) if f.endswith('.tsv')]\n",
        "\n",
        "print(\"Dataset Path:\", DATASET_PATH)\n",
        "print(\"Clips Path:\", CLIPS_PATH)\n",
        "print(\"TSV Files:\", TSV_FILES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXFMmNUEfl05",
        "outputId": "3773df28-c619-4551-a2fb-a46dc2a58c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset Path: /content/drive/MyDrive/Capstone/cv-corpus-20.0-2024-12-06/hy-AM\n",
            "Clips Path: /content/drive/MyDrive/Capstone/cv-corpus-20.0-2024-12-06/hy-AM/clips\n",
            "TSV Files: ['clip_durations.tsv', 'invalidated.tsv', 'test.tsv', 'validated.tsv', 'other.tsv', 'train.tsv', 'dev.tsv', 'reported.tsv', 'validated_sentences.tsv', 'unvalidated_sentences.tsv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert MP3 to WAV**"
      ],
      "metadata": {
        "id": "SW2ru_ZtfzJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "OUTPUT_WAV_PATH = os.path.join(DATASET_PATH, \"wav_clips\")\n",
        "\n",
        "#Create directory for WAV files\n",
        "os.makedirs(OUTPUT_WAV_PATH, exist_ok=True)\n",
        "\n",
        "def convert_mp3_to_wav(mp3_file, wav_file, sr=16000):\n",
        "    y, _ = librosa.load(mp3_file, sr=sr)  #Load with 16kHz sample rate\n",
        "    sf.write(wav_file, y, sr)\n",
        "\n",
        "#Convert all the MP3 files\n",
        "for file in tqdm(os.listdir(CLIPS_PATH)):\n",
        "    if file.endswith(\".mp3\"):\n",
        "        mp3_path = os.path.join(CLIPS_PATH, file)\n",
        "        wav_path = os.path.join(OUTPUT_WAV_PATH, file.replace(\".mp3\", \".wav\"))\n",
        "        convert_mp3_to_wav(mp3_path, wav_path)\n",
        "\n",
        "print(\"MP3 to WAV conversion completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B2p2unOfw50",
        "outputId": "408e651b-c2b0-4fe7-d9d2-df48114fc87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 37303/37632 [3:24:26<02:01,  2.71it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "OUTPUT_WAV_PATH = os.path.join(DATASET_PATH, \"wav_clips\")\n",
        "os.makedirs(OUTPUT_WAV_PATH, exist_ok=True)\n",
        "\n",
        "#convert MP3 to WAV\n",
        "def convert_mp3_to_wav(mp3_file, wav_file, sr=16000):\n",
        "    try:\n",
        "        y, _ = librosa.load(mp3_file, sr=sr)\n",
        "        sf.write(wav_file, y, sr)  #Save as WAV\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {mp3_file}: {e}\")\n",
        "\n",
        "#List MP3 and WAV files\n",
        "mp3_files = set([f for f in os.listdir(CLIPS_PATH) if f.endswith(\".mp3\")])\n",
        "wav_files = set([f.replace(\".wav\", \".mp3\") for f in os.listdir(OUTPUT_WAV_PATH) if f.endswith(\".wav\")])\n",
        "\n",
        "#Find missing conversions\n",
        "missing_files = mp3_files - wav_files\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"Resuming conversion for {len(missing_files)} missing files...\")\n",
        "    for file in tqdm(missing_files):\n",
        "        mp3_path = os.path.join(CLIPS_PATH, file)\n",
        "        wav_path = os.path.join(OUTPUT_WAV_PATH, file.replace(\".mp3\", \".wav\"))\n",
        "        convert_mp3_to_wav(mp3_path, wav_path)\n",
        "    print(\"Conversion of missing files completed!\")\n",
        "else:\n",
        "    print(\"All files are already converted!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdACcG3af2AF",
        "outputId": "c961eccf-3454-4fae-ba2e-02cd4bd41eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files are already converted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "#Count WAV files to check if everything is converted\n",
        "\n",
        "wav_files = [f for f in os.listdir(OUTPUT_WAV_PATH) if f.endswith(\".wav\")]\n",
        "wav_count = len(wav_files)\n",
        "\n",
        "print(f\"Total WAV files: {wav_count}\")\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO_hqlWpXXbV",
        "outputId": "7cd094d6-e9e1-4535-da1e-bfddc1bba8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total WAV files: 37632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Load and inspect the *train.tsv* file**"
      ],
      "metadata": {
        "id": "wUaTRnTpRICr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "TSV_PATH = os.path.join(DATASET_PATH, \"train.tsv\")\n",
        "df = pd.read_csv(TSV_PATH, sep=\"\\t\")\n",
        "\n",
        "#Display first few rows\n",
        "print(\"First 5 Rows of train.tsv:\")\n",
        "print(df.head())\n",
        "\n",
        "#Show column names\n",
        "print(\"\\nColumn Names in Dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "#Check for missing values\n",
        "print(\"\\nMissing Values in Dataset:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "lkQA9iUkRERS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Unique Samples & Distribution**"
      ],
      "metadata": {
        "id": "JOI0UxtpR2yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#total number of samples\n",
        "print(f\"\\nTotal Samples: {len(df)}\")\n",
        "\n",
        "#unique sentences (sometimes duplicates exist)\n",
        "print(f\"Unique Transcriptions: {df['sentence'].nunique()}\")\n",
        "\n",
        "#dataset statistics\n",
        "print(\"\\nDataset Summary:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtbiWONQXoB2",
        "outputId": "73718f9a-942a-40ce-a02b-79e14eda3544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Samples: 9270\n",
            "Unique Transcriptions: 9270\n",
            "\n",
            "Dataset Summary:\n",
            "       sentence_domain     up_votes   down_votes  variant  segment\n",
            "count              0.0  9270.000000  9270.000000      0.0      0.0\n",
            "mean               NaN     2.792880     0.109061      NaN      NaN\n",
            "std                NaN     1.326767     0.427345      NaN      NaN\n",
            "min                NaN     2.000000     0.000000      NaN      NaN\n",
            "25%                NaN     2.000000     0.000000      NaN      NaN\n",
            "50%                NaN     2.000000     0.000000      NaN      NaN\n",
            "75%                NaN     4.000000     0.000000      NaN      NaN\n",
            "max                NaN    12.000000     6.000000      NaN      NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All 9270 samples are unique → No duplicate sentences, which is good for training."
      ],
      "metadata": {
        "id": "neLZoPZuSZfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify Audio-Text Alignment**"
      ],
      "metadata": {
        "id": "mo0iHnVFR_LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "WAV_PATH = os.path.join(DATASET_PATH, \"wav_clips\")\n",
        "\n",
        "#available WAV files\n",
        "wav_files = set(os.listdir(WAV_PATH))\n",
        "\n",
        "#check how many audio files match the dataset\n",
        "matched = df[\"path\"].apply(lambda x: x.replace(\".mp3\", \".wav\") in wav_files)\n",
        "print(f\"\\nMatched Audio Files: {matched.sum()} / {len(df)}\")\n",
        "\n",
        "#rows where audio files are missing\n",
        "missing_audio = df[~matched]\n",
        "print(f\"\\nMissing Audio Files: {len(missing_audio)}\")\n",
        "print(missing_audio.head())\n",
        "\n",
        "#missing files report\n",
        "missing_audio.to_csv(os.path.join(DATASET_PATH, \"missing_audio_files.csv\"), index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PF1sbkWR5rF",
        "outputId": "d25f4089-cd9b-45b7-a538-7324a1f43725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matched Audio Files: 9270 / 9270\n",
            "\n",
            "Missing Audio Files: 0\n",
            "Empty DataFrame\n",
            "Columns: [client_id, path, sentence_id, sentence, sentence_domain, up_votes, down_votes, age, gender, accents, variant, locale, segment]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All 9270 files are found → No missing WAV files."
      ],
      "metadata": {
        "id": "3wc9DMWwSgxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keep Only Relevant Columns**"
      ],
      "metadata": {
        "id": "jPmSooFESsz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only useful columns\n",
        "filtered_df = df[[\"path\", \"sentence\"]].copy()\n",
        "\n",
        "#replace MP3 with WAV filenames\n",
        "filtered_df[\"path\"] = filtered_df[\"path\"].apply(lambda x: x.replace(\".mp3\", \".wav\"))\n",
        "\n",
        "filtered_df.to_csv(os.path.join(DATASET_PATH, \"filtered_train.csv\"), index=False)\n",
        "print(f\"Filtered dataset saved with {len(filtered_df)} samples!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBuIpviFSCVS",
        "outputId": "650ed420-1bdd-4484-d945-1ad0454b1a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset saved with 9270 samples!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean the Transcriptions**"
      ],
      "metadata": {
        "id": "Z4QCuwK-S21q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  #Convert to lowercase\n",
        "    text = re.sub(r\"[^ա-ֆԱ-Ֆa-zA-Z0-9\\s]\", \"\", text)  #Remove special characters\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  #Remove extra spaces\n",
        "    return text\n",
        "\n",
        "filtered_df[\"sentence\"] = filtered_df[\"sentence\"].apply(clean_text)\n",
        "filtered_df.to_csv(os.path.join(DATASET_PATH, \"cleaned_train.csv\"), index=False)\n",
        "\n",
        "print(\"Text cleaning completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-5PyzYZSvLS",
        "outputId": "531b3c90-e87b-459c-ee4b-6a5be2e55dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text cleaning completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter Out Bad Audio Samples**"
      ],
      "metadata": {
        "id": "S7fechDRS_4z"
      }
    },
    {
      "source": [
        "import librosa\n",
        "from tqdm import tqdm\n",
        "\n",
        "WAV_PATH = os.path.join(DATASET_PATH, \"wav_clips\")\n",
        "\n",
        "valid_data = []\n",
        "min_duration = 0.5  # Min valid duration (seconds)\n",
        "max_duration = 15.0  # Max valid duration (seconds)\n",
        "\n",
        "corrupt_files = []\n",
        "\n",
        "for index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n",
        "    wav_file = os.path.join(WAV_PATH, row[\"path\"])\n",
        "\n",
        "    if os.path.exists(wav_file):\n",
        "        try:\n",
        "            y, sr = librosa.load(wav_file, sr=None)\n",
        "            duration = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "            #only valid durations\n",
        "            if min_duration <= duration <= max_duration:\n",
        "                valid_data.append((row[\"path\"], row[\"sentence\"], duration))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"!!!Skipping {wav_file} due to error: {e}!!!\")\n",
        "            corrupt_files.append(wav_file)\n",
        "\n",
        "#Convert to DataFrame\n",
        "final_df = pd.DataFrame(valid_data, columns=[\"wav_path\", \"transcript\", \"duration\"])\n",
        "\n",
        "#Save final processed dataset\n",
        "final_df.to_csv(os.path.join(DATASET_PATH, \"final_train.csv\"), index=False)\n",
        "\n",
        "#Save list of corrupt files\n",
        "if corrupt_files:\n",
        "    with open(os.path.join(DATASET_PATH, \"corrupt_files.txt\"), \"w\") as f:\n",
        "        for file in corrupt_files:\n",
        "            f.write(file + \"\\n\")\n",
        "\n",
        "print(f\"Final dataset saved with {len(final_df)} valid samples!\")\n",
        "print(f\"Skipped {len(corrupt_files)} corrupted files. See 'corrupt_files.txt' for details.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYb3IE-cZ5sN",
        "outputId": "087932db-0fde-4d2a-bf9e-871490e6c0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 7964/9270 [00:23<00:03, 350.84it/s]<ipython-input-14-3d5ae84ea675>:17: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(wav_file, sr=None)\n",
            " 87%|████████▋ | 8041/9270 [00:24<00:03, 354.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!!Skipping /content/drive/MyDrive/Capstone/cv-corpus-20.0-2024-12-06/hy-AM/wav_clips/common_voice_hy-AM_39460081.wav due to error: !!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9270/9270 [04:33<00:00, 33.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset saved with 9269 valid samples!\n",
            "Skipped 1 corrupted files. See 'corrupt_files.txt' for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split final_train.csv into Train/Validation**"
      ],
      "metadata": {
        "id": "C_9y3RGBe0Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "train_full_df = pd.read_csv(os.path.join(DATASET_PATH, \"final_train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(DATASET_PATH, \"test.tsv\"), sep=\"\\t\")\n",
        "#90% train, 10% validation\n",
        "train_df, new_val_df = train_test_split(train_full_df, test_size=0.1, random_state=42)\n",
        "\n",
        "dev_df = pd.read_csv(os.path.join(DATASET_PATH, \"dev.tsv\"), sep=\"\\t\")[[\"path\", \"sentence\"]]\n",
        "dev_df[\"path\"] = dev_df[\"path\"].apply(lambda x: x.replace(\".mp3\", \".wav\"))\n",
        "\n",
        "#Combine new validation split with the existing validation set\n",
        "final_val_df = pd.concat([dev_df, new_val_df])\n",
        "\n",
        "#Saving the train and validation sets\n",
        "train_df.to_csv(os.path.join(DATASET_PATH, \"train.csv\"), index=False)\n",
        "final_val_df.to_csv(os.path.join(DATASET_PATH, \"validation.csv\"), index=False)\n",
        "\n",
        "print(f\"New Train Set: {len(train_df)} samples\")\n",
        "print(f\"Final Validation Set: {len(final_val_df)} samples (Including dev.tsv)\")\n",
        "print(f\"Test Set: {len(test_df)} samples\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhj4QnEyeTpf",
        "outputId": "24f433f3-ccbd-4c46-f23f-d6da410863fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Train Set: 8342 samples\n",
            "Final Validation Set: 6633 samples (Including dev.tsv)\n",
            "Test Set: 5856 samples\n"
          ]
        }
      ]
    }
  ]
}