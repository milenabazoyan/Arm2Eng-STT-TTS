{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "it's generally recommended to convert MP3 files to WAV format, preferably with a consistent sampling rate (e.g., 16kHz, mono) to ensure compatibility with training models"
      ],
      "metadata": {
        "id": "PUUe11mKfFLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps for Data Preprocessing:**\n",
        "\n",
        "---\n",
        "\n",
        "1. Convert MP3 files to WAV (16kHz, mono)\n",
        "\n",
        "2. Load and inspect the dataset (TSV files)\n",
        "\n",
        "3. Align audio files with text transcriptions\n",
        "\n",
        "4. Remove invalid or low-quality samples\n",
        "\n",
        "5. Normalize and clean text data\n",
        "\n",
        "6. Split the train data into Train/Validation"
      ],
      "metadata": {
        "id": "K0GLTb01fOF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BwkSgHWPfs9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1v2hUEECZkJH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google Drive & Set Paths**"
      ],
      "metadata": {
        "id": "oerVXOWyfrqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "#Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Define dataset paths\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Capstone/cv-corpus-20.0-2024-12-06/hy-AM\"\n",
        "CLIPS_PATH = os.path.join(DATASET_PATH, \"clips\")\n",
        "TSV_FILES = [f for f in os.listdir(DATASET_PATH) if f.endswith('.tsv')]\n",
        "\n",
        "print(\"Dataset Path:\", DATASET_PATH)\n",
        "print(\"Clips Path:\", CLIPS_PATH)\n",
        "print(\"TSV Files:\", TSV_FILES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXFMmNUEfl05",
        "outputId": "b4378498-ed53-452e-d3da-7760ffa86e08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset Path: /content/drive/MyDrive/Capstone/cv-corpus-20.0-2024-12-06/hy-AM\n",
            "Clips Path: /content/drive/MyDrive/Capstone/cv-corpus-20.0-2024-12-06/hy-AM/clips\n",
            "TSV Files: ['clip_durations.tsv', 'invalidated.tsv', 'test.tsv', 'validated.tsv', 'other.tsv', 'train.tsv', 'dev.tsv', 'reported.tsv', 'validated_sentences.tsv', 'unvalidated_sentences.tsv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert MP3 to WAV**"
      ],
      "metadata": {
        "id": "SW2ru_ZtfzJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_WAV_PATH = os.path.join(DATASET_PATH, \"wav_clips\")\n",
        "os.makedirs(OUTPUT_WAV_PATH, exist_ok=True)\n",
        "\n",
        "#convert MP3 to WAV\n",
        "def convert_mp3_to_wav(mp3_file, wav_file, sr=16000):\n",
        "    try:\n",
        "        y, _ = librosa.load(mp3_file, sr=sr)\n",
        "        sf.write(wav_file, y, sr)  #Save as WAV\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {mp3_file}: {e}\")\n",
        "\n",
        "#List MP3 and WAV files\n",
        "mp3_files = set([f for f in os.listdir(CLIPS_PATH) if f.endswith(\".mp3\")])\n",
        "wav_files = set([f.replace(\".wav\", \".mp3\") for f in os.listdir(OUTPUT_WAV_PATH) if f.endswith(\".wav\")])\n",
        "\n",
        "#Find missing conversions\n",
        "missing_files = mp3_files - wav_files\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"Resuming conversion for {len(missing_files)} missing files...\")\n",
        "    for file in tqdm(missing_files):\n",
        "        mp3_path = os.path.join(CLIPS_PATH, file)\n",
        "        wav_path = os.path.join(OUTPUT_WAV_PATH, file.replace(\".mp3\", \".wav\"))\n",
        "        convert_mp3_to_wav(mp3_path, wav_path)\n",
        "    print(\"Conversion of missing files completed!\")\n",
        "else:\n",
        "    print(\"All files are already converted!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdACcG3af2AF",
        "outputId": "e1443158-57bf-4194-ea77-2005d8c8fad0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files are already converted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Count WAV files to check if everything is converted\n",
        "\n",
        "wav_files = [f for f in os.listdir(OUTPUT_WAV_PATH) if f.endswith(\".wav\")]\n",
        "wav_count = len(wav_files)\n",
        "\n",
        "print(f\"Total WAV files: {wav_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO_hqlWpXXbV",
        "outputId": "51bcc565-8b8d-4bde-82dc-540a302313ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total WAV files: 37632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Load and inspect the *train.tsv* file**"
      ],
      "metadata": {
        "id": "wUaTRnTpRICr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TSV_PATH = os.path.join(DATASET_PATH, \"train.tsv\")\n",
        "df = pd.read_csv(TSV_PATH, sep=\"\\t\")\n",
        "\n",
        "#Display first few rows\n",
        "print(\"First 5 Rows of train.tsv:\")\n",
        "print(df.head())\n",
        "\n",
        "#Show column names\n",
        "print(\"\\nColumn Names in Dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "#Check for missing values\n",
        "print(\"\\nMissing Values in Dataset:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "lkQA9iUkRERS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5bdc93-8f37-4df3-9679-6d221beb3d40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 Rows of train.tsv:\n",
            "                                           client_id  \\\n",
            "0  f0aba38a8ab8705a40d05d96829ded5738a7eec7a9a182...   \n",
            "1  f0aba38a8ab8705a40d05d96829ded5738a7eec7a9a182...   \n",
            "2  f0aba38a8ab8705a40d05d96829ded5738a7eec7a9a182...   \n",
            "3  f0aba38a8ab8705a40d05d96829ded5738a7eec7a9a182...   \n",
            "4  f0aba38a8ab8705a40d05d96829ded5738a7eec7a9a182...   \n",
            "\n",
            "                              path  \\\n",
            "0  common_voice_hy-AM_26078953.mp3   \n",
            "1  common_voice_hy-AM_26078954.mp3   \n",
            "2  common_voice_hy-AM_26078955.mp3   \n",
            "3  common_voice_hy-AM_26078956.mp3   \n",
            "4  common_voice_hy-AM_26078957.mp3   \n",
            "\n",
            "                                         sentence_id  \\\n",
            "0  00014f9fed6163512d57623235a957a437359074b4fb76...   \n",
            "1  007874c957da34754fbbea93f069b5acdc65d1a31c5731...   \n",
            "2  007d6389e52bd5bec1b7de98468981aac7cbd063b79222...   \n",
            "3  00404cb33e31b3b8a5c1694596efbaf09797c10db3dd9b...   \n",
            "4  005f7b60d6d50c3294a90bb34d8c93d627521103cc7659...   \n",
            "\n",
            "                                            sentence  sentence_domain  \\\n",
            "0                           Ժաբոն օձիքի տարատեսակ է։              NaN   \n",
            "1  Հետպատերազմյան շրջանում դարձել է պրոֆեսիոնալ լ...              NaN   \n",
            "2  Ան նաեւ աջակցած է բժիշկներ առանց սահմաններու կ...              NaN   \n",
            "3  Մասնակիցները հնարավորություններ են փնտրում աշխ...              NaN   \n",
            "4  Ժամանակ առ ժամանակ եղել է կենտրոնացված իշխանու...              NaN   \n",
            "\n",
            "   up_votes  down_votes       age           gender accents  variant locale  \\\n",
            "0         2           0  thirties  female_feminine     NaN      NaN  hy-AM   \n",
            "1         2           0  thirties  female_feminine     NaN      NaN  hy-AM   \n",
            "2         2           1  thirties  female_feminine     NaN      NaN  hy-AM   \n",
            "3         2           0  thirties  female_feminine     NaN      NaN  hy-AM   \n",
            "4         2           0  thirties  female_feminine     NaN      NaN  hy-AM   \n",
            "\n",
            "   segment  \n",
            "0      NaN  \n",
            "1      NaN  \n",
            "2      NaN  \n",
            "3      NaN  \n",
            "4      NaN  \n",
            "\n",
            "Column Names in Dataset:\n",
            "Index(['client_id', 'path', 'sentence_id', 'sentence', 'sentence_domain',\n",
            "       'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant',\n",
            "       'locale', 'segment'],\n",
            "      dtype='object')\n",
            "\n",
            "Missing Values in Dataset:\n",
            "client_id             0\n",
            "path                  0\n",
            "sentence_id           0\n",
            "sentence              0\n",
            "sentence_domain    9270\n",
            "up_votes              0\n",
            "down_votes            0\n",
            "age                 819\n",
            "gender             1419\n",
            "accents            6431\n",
            "variant            9270\n",
            "locale                0\n",
            "segment            9270\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Unique Samples & Distribution**"
      ],
      "metadata": {
        "id": "JOI0UxtpR2yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#total number of samples\n",
        "print(f\"\\nTotal Samples: {len(df)}\")\n",
        "\n",
        "#unique sentences (sometimes duplicates exist)\n",
        "print(f\"Unique Transcriptions: {df['sentence'].nunique()}\")\n",
        "\n",
        "#dataset statistics\n",
        "print(\"\\nDataset Summary:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtbiWONQXoB2",
        "outputId": "3bb0be56-71f5-45b6-f581-6561586855e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Samples: 9270\n",
            "Unique Transcriptions: 9270\n",
            "\n",
            "Dataset Summary:\n",
            "       sentence_domain     up_votes   down_votes  variant  segment\n",
            "count              0.0  9270.000000  9270.000000      0.0      0.0\n",
            "mean               NaN     2.792880     0.109061      NaN      NaN\n",
            "std                NaN     1.326767     0.427345      NaN      NaN\n",
            "min                NaN     2.000000     0.000000      NaN      NaN\n",
            "25%                NaN     2.000000     0.000000      NaN      NaN\n",
            "50%                NaN     2.000000     0.000000      NaN      NaN\n",
            "75%                NaN     4.000000     0.000000      NaN      NaN\n",
            "max                NaN    12.000000     6.000000      NaN      NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All 9270 samples are unique -> No duplicate sentences, which is good for training."
      ],
      "metadata": {
        "id": "neLZoPZuSZfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify Audio-Text Alignment**"
      ],
      "metadata": {
        "id": "mo0iHnVFR_LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WAV_PATH = os.path.join(DATASET_PATH, \"wav_clips\")\n",
        "\n",
        "#available WAV files\n",
        "wav_files = set(os.listdir(WAV_PATH))\n",
        "\n",
        "#check how many audio files match the dataset\n",
        "matched = df[\"path\"].apply(lambda x: x.replace(\".mp3\", \".wav\") in wav_files)\n",
        "print(f\"\\nMatched Audio Files: {matched.sum()} / {len(df)}\")\n",
        "\n",
        "#rows where audio files are missing\n",
        "missing_audio = df[~matched]\n",
        "print(f\"\\nMissing Audio Files: {len(missing_audio)}\")\n",
        "print(missing_audio.head())\n",
        "\n",
        "#missing files report\n",
        "missing_audio.to_csv(os.path.join(DATASET_PATH, \"missing_audio_files.csv\"), index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PF1sbkWR5rF",
        "outputId": "dac89ef9-2c3e-4891-b811-981cf980ce72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matched Audio Files: 9270 / 9270\n",
            "\n",
            "Missing Audio Files: 0\n",
            "Empty DataFrame\n",
            "Columns: [client_id, path, sentence_id, sentence, sentence_domain, up_votes, down_votes, age, gender, accents, variant, locale, segment]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All 9270 files are found -> No missing WAV files."
      ],
      "metadata": {
        "id": "3wc9DMWwSgxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keep Only Relevant Columns**"
      ],
      "metadata": {
        "id": "jPmSooFESsz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only useful columns\n",
        "filtered_df = df[[\"path\", \"sentence\"]].copy()\n",
        "\n",
        "#replace MP3 with WAV filenames\n",
        "filtered_df[\"path\"] = filtered_df[\"path\"].apply(lambda x: x.replace(\".mp3\", \".wav\"))\n",
        "\n",
        "filtered_df.to_csv(os.path.join(DATASET_PATH, \"filtered_train.csv\"), index=False)\n",
        "print(f\"Filtered dataset saved with {len(filtered_df)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBuIpviFSCVS",
        "outputId": "155eff91-182b-4492-a132-600529804760"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset saved with 9270 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean and Filter**"
      ],
      "metadata": {
        "id": "Z4QCuwK-S21q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#keeping the uppercase and punctuation in the text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  #normalize whitespace\n",
        "    return text\n",
        "\n",
        "filtered_df[\"sentence\"] = filtered_df[\"sentence\"].apply(clean_text)\n",
        "filtered_df.to_csv(os.path.join(DATASET_PATH, \"cleaned_train.csv\"), index=False)\n",
        "print(\"Cleaned text saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-5PyzYZSvLS",
        "outputId": "4a12e142-1c6d-479b-add0-85e2f0096714"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter Out Bad Audio Samples**"
      ],
      "metadata": {
        "id": "S7fechDRS_4z"
      }
    },
    {
      "source": [
        "WAV_PATH = os.path.join(DATASET_PATH, \"wav_clips\")\n",
        "valid_data = []\n",
        "corrupt_files = []\n",
        "\n",
        "for _, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n",
        "    wav_path = os.path.join(WAV_PATH, row[\"path\"])\n",
        "    if os.path.exists(wav_path):\n",
        "        try:\n",
        "            y, sr = librosa.load(wav_path, sr=None)\n",
        "            duration = librosa.get_duration(y=y, sr=sr)\n",
        "            if 0.5 <= duration <= 15.0:\n",
        "                valid_data.append((row[\"path\"], row[\"sentence\"], duration))\n",
        "        except Exception as e:\n",
        "            corrupt_files.append(wav_path)\n",
        "\n",
        "final_df = pd.DataFrame(valid_data, columns=[\"wav_path\", \"transcript\", \"duration\"])\n",
        "final_df.to_csv(os.path.join(DATASET_PATH, \"final_train.csv\"), index=False)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYb3IE-cZ5sN",
        "outputId": "fbe11b9d-70e7-4af5-ff84-11a9f35b9769"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 7971/9270 [1:57:08<16:05,  1.34it/s]<ipython-input-13-03d600700e08>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(wav_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "100%|██████████| 9270/9270 [2:14:30<00:00,  1.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Final Dataset into Train/Validation**"
      ],
      "metadata": {
        "id": "C_9y3RGBe0Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.read_csv(os.path.join(DATASET_PATH, \"final_train.csv\"))\n",
        "\n",
        "#Train/validation split\n",
        "train_df, new_val_df = train_test_split(final_df, test_size=0.1, random_state=42)\n",
        "\n",
        "dev_df = pd.read_csv(os.path.join(DATASET_PATH, \"dev.tsv\"), sep=\"\\t\")[[\"path\", \"sentence\"]]\n",
        "dev_df[\"path\"] = dev_df[\"path\"].apply(lambda x: x.replace(\".mp3\", \".wav\"))\n",
        "dev_df[\"duration\"] = -1  #optional placeholder\n",
        "dev_df.columns = [\"wav_path\", \"transcript\", \"duration\"]\n",
        "\n",
        "final_val_df = pd.concat([new_val_df, dev_df])\n",
        "\n",
        "train_df.to_csv(os.path.join(DATASET_PATH, \"train.csv\"), index=False)\n",
        "final_val_df.to_csv(os.path.join(DATASET_PATH, \"validation.csv\"), index=False)"
      ],
      "metadata": {
        "id": "Uhj4QnEyeTpf"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}